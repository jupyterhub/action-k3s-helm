# This is the GitHub Action definition file, similar to a GitHub Workflow but
# different. Noteworthy differences are for example that we cannot set
# defaults.run.shell=bash, and any output we set in collective steps must be
# re-mapped under the outputs field.
#
# yamllint disable rule:line-length
#
# Reference: https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions
#
---
name: K3S with Calico and Helm
description: |
  Install Kubernetes (K3S) and Helm 3.
  Includes Calico network plugin for network policy support.

branding:
  icon: server
  color: purple

# Copied from
# https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/08c13609c1d0c6cb07d45d49d0a876100cf941eb/ci/common
# Thanks @consideratio !

inputs:
  k3s-version:
    description: K3S version (https://github.com/rancher/k3s/releases)
    required: false
    default: ""
  k3s-channel:
    description: K3S channel (https://update.k3s.io/v1-release/channels)
    required: false
    default: ""
  helm-version:
    description: Helm 3 version (https://github.com/helm/helm/releases)
    required: false
    default: ""
  metrics-enabled:
    description: Enable or disable K3S metrics-server
    required: false
    default: "true"
  traefik-enabled:
    description: Enable or disable K3S Traefik ingress
    required: false
    default: "true"
  docker-enabled:
    description: Enable K3s to use the Docker daemon
    required: false
    default: "false"
  ip-mode:
    description: 'Switch between IPv4 and/or IPv6: "default", "dual" or "ipv6"'
    required: false
    default: default
  extra-setup-args:
    description: Addition arguments to be passed to the K3S setup script
    required: false
    default: ""

outputs:
  kubeconfig:
    description: Path to kubeconfig file
    value: ${{ steps.set-output.outputs.kubeconfig }}
  k3s-version:
    description: "Installed k3s version, such as v1.29.0+k3s1"
    value: "${{ steps.set-output.outputs.k3s-version }}"
  k8s-version:
    description: "Installed k8s version, such as v1.29.0"
    value: "${{ steps.set-output.outputs.k8s-version }}"
  calico-version:
    description: "Installed calico version, such as v3.28.1"
    value: "${{ steps.set-output.outputs.calico-version }}"
  helm-version:
    description: "Installed helm version, such as v3.13.0"
    value: "${{ steps.set-output.outputs.helm-version }}"

runs:
  using: "composite"
  steps:
    # https://rancher.com/docs/k3s/latest/en/installation/install-options/how-to-flags/
    #
    # NOTE: k3s has a Network Policy controller called kube-router, but it is
    #       not robust enough for use, so we disable it and install our own:
    #       calico. --flannel-backend=none should not be passed if we don't want
    #       to install our own CNI.
    #
    #       ref: https://github.com/rancher/k3s/issues/947#issuecomment-627641541
    #
    - name: Validate input
      run: |
        echo "::group::Validate input"
        if [[ -n "${{ inputs.k3s-version }}" && -n "${{ inputs.k3s-channel }}" ]]; then
          echo "k3s-version and k3s-channel must not be specified simultaneously!"
          exit 1
        fi
        echo "::endgroup::"
      shell: bash

    # https://docs.k3s.io/networking/basic-network-options#dual-stack-ipv4--ipv6-networking
    - name: Set IP mode variables
      run: |
        echo "::group::Setting IP variables"
        if [[ "${{ inputs.ip-mode }}" != "default" ]]; then
          NODE_IP4=$(ip -4 addr show eth0 | grep -oP '(?<=inet\s)([^/]+)')
          if [ -z "$NODE_IP4" ]; then
            echo "Failed to get node IP4"
            exit 1
          fi
          NODE_IP6=$(ip -6 addr show eth0 | grep -oP '(?<=inet6\s)([^/]+)')
          if [ -z "$NODE_IP6" ]; then
            echo "Failed to get node IP6"
            exit 1
          fi

          if [[ "${{ inputs.ip-mode }}" = "dual" ]]; then
            echo K3S_CLUSTER_CIDR="10.42.0.0/16,2001:cafe:42::/56"
            echo K3S_SERVICE_CIDR="10.43.0.0/16,2001:cafe:43::/112"
            echo K3S_NODE_IP="${NODE_IP4},{NODE_IP6}"
          elif [[ "${{ inputs.ip-mode }}" = "ipv6" ]]; then
            echo K3S_CLUSTER_CIDR="2001:cafe:42::/56"
            echo K3S_SERVICE_CIDR="2001:cafe:43::/112"
            echo K3S_NODE_IP="${NODE_IP6}"
          else
            echo "Invalid ip-mode: ${{ inputs.ip-mode }}"
            exit 1
          fi
        fi
        echo "K3S_CLUSTER_CIDR=$K3S_CLUSTER_CIDR" >> $GITHUB_ENV
        echo "K3S_SERVICE_CIDR=$K3S_SERVICE_CIDR" >> $GITHUB_ENV
        echo "K3S_NODE_IP=$K3S_NODE_IP" >> $GITHUB_ENV
        echo "::endgroup::"
      shell: bash

    # NOTE: We apply a workaround as of version 3.0.1 by passing
    #       --egress-selector-mode=disabled by default as not doing so following
    #       modern versions of k3s has led to issues with `kubectl exec` and
    #       `kubectl logs`.
    #
    #       For more details, see
    #       https://github.com/k3s-io/k3s/issues/5633
    #       and https://github.com/jupyterhub/action-k3s-helm/issues/59.
    #
    - name: Setup k3s ${{ inputs.k3s-version }}${{ inputs.k3s-channel }}
      run: |
        echo "::group::Setup k3s ${{ inputs.k3s-version }}${{ inputs.k3s-channel }}"
        if [[ "${{ inputs.metrics-enabled }}" != true ]]; then
          k3s_disable_metrics="--disable metrics-server"
        fi
        if [[ "${{ inputs.traefik-enabled }}" != true ]]; then
          k3s_disable_traefik="--disable traefik"
        fi
        if [[ "${{ inputs.docker-enabled }}" == true ]]; then
          k3s_docker=--docker
        fi
        # We want to provide a new default value for the --egress-selector-mode
        # flag to avoid an intermittent issue possibly not fully resolved:
        # https://github.com/k3s-io/k3s/issues/5633#issuecomment-1181424511.
        #
        # Details about the option available at
        # https://docs.k3s.io/installation/network-options#control-plane-egress-selector-configuration.
        #
        if [[ "${{ inputs.extra-setup-args }}" != *--egress-selector-mode* ]]; then
          default_extra_setup_args=--egress-selector-mode=disabled
        fi
        if [[ -n "$K3S_CLUSTER_CIDR" ]]; then
          k3s_cluster_cidr="--cluster-cidr=$K3S_CLUSTER_CIDR"
        fi
        if [[ -n "$K3S_SERVICE_CIDR" ]]; then
          k3s_service_cidr="--service-cidr=$K3S_SERVICE_CIDR"
        fi
        if [[ -n "$K3S_NODE_IP" ]]; then
          k3s_node_ip="--service-cidr=$K3S_NODE_IP"
        fi

        curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION="${{ inputs.k3s-version }}" INSTALL_K3S_CHANNEL="${{ inputs.k3s-channel }}" sh -s - \
          ${k3s_disable_metrics} \
          ${k3s_disable_traefik} \
          --disable-network-policy \
          --flannel-backend=none \
          ${k3s_docker} \
          ${k3s_cluster_cidr} \
          ${k3s_service_cidr} \
          ${k3s_node_ip} \
          ${{ inputs.extra-setup-args }} \
          ${default_extra_setup_args}
        echo "::endgroup::"
      shell: bash

    # By providing a kubeconfig owned by the current user with 600 permissions,
    # kubectl becomes usable without sudo, and helm won't emit warnings about
    # bloated access to group/world.
    - name: Prepare a kubeconfig in ~/.kube/config
      run: |
        echo "::group::Prepare a kubeconfig in ~/.kube/config"
        mkdir -p ~/.kube
        sudo cat /etc/rancher/k3s/k3s.yaml > "$HOME/.kube/config"
        chmod 600 "$HOME/.kube/config"
        echo "KUBECONFIG=$HOME/.kube/config" >> $GITHUB_ENV
        echo "::endgroup::"
      shell: bash

    # Install calico as a CNI to enforce our NetworkPolicies. Note that canal
    # could do this job as well.
    #
    # ref: https://rancher.com/docs/k3s/latest/en/installation/network-options/
    #
    # IPv6: https://docs.tigera.io/calico/latest/networking/ipam/ipv6
    #
    - name: Setup calico
      run: |
        echo "::group::Setup calico"
        # Download calico.yaml k8s and split into separate manifests
        curl -sfL --output /tmp/calico.yaml https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml
        mkdir calico
        cd calico
        yq -s '"\(.kind)-\(.metadata.name).yaml"' /tmp/calico.yaml

        # ConfigMap/calico-config: Look for `"type": "calico"` and add
        # `"container_settings": ...` on the next line
        sed -i.bak '/"type": "calico"/a\
                  "container_settings": {"allow_ip_forwarding": true},'\
          ConfigMap-calico-config.yaml

        # Optionally configure IPv6
        # https://docs.tigera.io/calico/latest/networking/ipam/ipv6
        # ConfigMap/calico-config: Look for `"type": "calico-ipam"` and add
        # additional properties
        if [[ "${{ inputs.ip-mode }}" = "dual" ]]; then
          sed -i '/"type": "calico-ipam"/a\
                    , "assign_ipv4": "true", "assign_ipv6": "true"'\
            ConfigMap-calico-config.yaml
        fi
        if [[ "${{ inputs.ip-mode }}" = "ipv6" ]]; then
          sed -i '/"type": "calico-ipam"/a\
                    , "assign_ipv4": "false", "assign_ipv6": "true"'\
            ConfigMap-calico-config.yaml
        fi

        if [[ "${{ inputs.ip-mode }}" = "dual" || "${{ inputs.ip-mode }}" = "ipv6" ]]; then
          # DaemonSet/calico-node: Modify and add environment variables
          sed -i.bak -re '/- name: FELIX_IPV6SUPPORT/{n; s/"false"/"true"\n\
                    - name: IP6\n\
                      value: autodetect\n\
                    - name: CALICO_IPV6POOL_CIDR\n\
                      value: "2001:cafe:42::\/56"/}'\
            DaemonSet-calico-node.yaml
        fi

        for f in *.yaml.bak; do
          diff -u "$f" "${f%.bak}" || :
        done

        cat ./*.yaml | kubectl apply -f -
        echo "::endgroup::"
      shell: bash

    # There will be some waiting for calico to make the k8s Nodes ready and for
    # the k3s related pods to start and become ready, so there is time to
    # install Helm at this point for example.
    - name: Setup Helm ${{ inputs.helm-version }}
      run: |
        echo "::group::Setup Helm ${{ inputs.helm-version }}"
        curl -sf https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | DESIRED_VERSION="${{ inputs.helm-version }}" bash
        echo "::endgroup::"
      shell: bash

    - name: Set version output
      id: set-output
      run: |
        echo "::group::Set version output"
        echo "kubeconfig=$HOME/.kube/config" >> $GITHUB_OUTPUT
        echo "k3s-version=$(k3s --version | grep --max-count=1 'k3s' | sed 's/.*\(v[0-9][^ ]*\).*/\1/')" >> $GITHUB_OUTPUT
        echo "k8s-version=$(k3s --version | grep --max-count=1 'k3s' | sed 's/.*\(v[0-9][^+]*\).*/\1/')" >> $GITHUB_OUTPUT
        echo "calico-version=$(cat /tmp/calico.yaml | grep --max-count=1 'calico/cni:v' | sed 's/.*calico\/cni:\(.*\)/\1/')" >> $GITHUB_OUTPUT
        echo "helm-version=$(helm version --short | sed 's/\([^+]*\).*/\1/')" >> $GITHUB_OUTPUT
        echo "::endgroup::"
      shell: bash

    - name: Wait for calico, coredns, metrics server, traefik
      run: |
        echo "::group::Wait for daemonset/calico-node"
        kubectl rollout status --watch --timeout=5m daemonset/calico-node -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/calico-kube-controllers"
        kubectl rollout status --watch --timeout=5m deployment/calico-kube-controllers -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/coredns"
        kubectl rollout status --watch --timeout=5m deployment/coredns -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/metrics-server"
        if [[ "${{ inputs.metrics-enabled }}" == true ]]; then
          kubectl rollout status --watch --timeout=5m deployment/metrics-server -n kube-system
        fi
        echo "::endgroup::"

        echo "::group::Wait for deployment/traefik"
        if [[ "${{ inputs.traefik-enabled }}" == true ]]; then
          # NOTE: Different versions of k3s install traefik in different ways,
          #       by waiting for these jobs if they exist, we will be fine no
          #       matter what.
          kubectl wait --for=condition=complete --timeout=5m job/helm-install-traefik-crd -n kube-system || true
          kubectl wait --for=condition=complete --timeout=5m job/helm-install-traefik -n kube-system || true
          kubectl rollout status --watch --timeout=5m deployment/traefik -n kube-system
        fi
        echo "::endgroup::"
      shell: bash
