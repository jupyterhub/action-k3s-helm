# This is the GitHub Action definition file, similar to a GitHub Workflow but
# different. Noteworthy differences are for example that we cannot set
# defaults.run.shell=bash, and any output we set in collective steps must be
# re-mapped under the outputs field.
#
# yamllint disable rule:line-length
#
# Reference: https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions
#
---
name: K3S with Calico and Helm
description: |
  Install Kubernetes (K3S) and Helm 3.
  Includes Calico network plugin for network policy support.

branding:
  icon: server
  color: purple

# Copied from
# https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/08c13609c1d0c6cb07d45d49d0a876100cf941eb/ci/common
# Thanks @consideratio !

inputs:
  k3s-version:
    description: K3S version (https://github.com/rancher/k3s/releases)
    required: false
    default: ""
  k3s-channel:
    description: K3S channel (https://update.k3s.io/v1-release/channels)
    required: false
    default: ""
  helm-version:
    description: Helm 3 version (https://github.com/helm/helm/releases)
    required: false
    default: ""
  metrics-enabled:
    description: Enable or disable K3S metrics-server
    required: false
    default: "true"
  traefik-enabled:
    description: Enable or disable K3S Traefik ingress
    required: false
    default: "true"
  docker-enabled:
    description: Enable K3s to use the Docker daemon
    required: false
    default: "false"
  extra-setup-args:
    description: Addition arguments to be passed to the K3S setup script
    required: false
    default: ""

outputs:
  kubeconfig:
    description: Path to kubeconfig file
    value: ${{ steps.set-output.outputs.kubeconfig }}
  k3s-version:
    description: "Installed k3s version, such as v1.20.0+k3s2"
    value: "${{ steps.set-output.outputs.k3s-version }}"
  k8s-version:
    description: "Installed k8s version, such as v1.20.0"
    value: "${{ steps.set-output.outputs.k8s-version }}"
  calico-version:
    description: "Installed calico version, such as v3.20.2"
    value: "${{ steps.set-output.outputs.calico-version }}"
  helm-version:
    description: "Installed helm version, such as v3.4.2"
    value: "${{ steps.set-output.outputs.helm-version }}"

runs:
  using: "composite"
  steps:
    # https://rancher.com/docs/k3s/latest/en/installation/install-options/how-to-flags/
    #
    # NOTE: k3s has a Network Policy controller called kube-router, but it is
    #       not robust enough for use, so we disable it and install our own:
    #       calico. --flannel-backend=none should not be passed if we don't want
    #       to install our own CNI.
    #
    #       ref: https://github.com/rancher/k3s/issues/947#issuecomment-627641541
    #
    - name: Validate input
      run: |
        echo "::group::Validate input"
        if [[ -n "${{ inputs.k3s-version }}" && -n "${{ inputs.k3s-channel }}" ]]; then
          echo "k3s-version and k3s-channel must not be specified simultaneously!"
          exit 1
        fi
        echo "::endgroup::"
      shell: bash

    # NOTE: The sed substitution operation is to run cri-dockerd in a way that
    #       makes it work with calico as a CNI. This was based on
    #       https://github.com/Mirantis/cri-dockerd/issues/42.
    #
    - name: Setup cri-dockerd as a dockershim
      if: inputs.docker-enabled == 'true'
      env:
        CRI_DOCKERD_VERSION: "0.2.5"
      run: |
        cd /tmp

        wget -qO- https://github.com/Mirantis/cri-dockerd/releases/download/v${CRI_DOCKERD_VERSION}/cri-dockerd-${CRI_DOCKERD_VERSION}.amd64.tgz | tar -xvz --strip-components=1
        wget -q https://raw.githubusercontent.com/Mirantis/cri-dockerd/v${CRI_DOCKERD_VERSION}/packaging/systemd/cri-docker.service
        wget -q https://raw.githubusercontent.com/Mirantis/cri-dockerd/v${CRI_DOCKERD_VERSION}/packaging/systemd/cri-docker.socket
        sudo mv cri-dockerd /usr/bin/
        sudo mv cri-docker.socket /etc/systemd/system/
        sudo mv cri-docker.service /etc/systemd/system/

        sudo sed --in-place --expression \
            's,--network-plugin=,--network-plugin=cni --cni-bin-dir=/opt/cni/bin --cni-cache-dir=/var/lib/cni/cache --cni-conf-dir=/etc/cni/net.d,' \
            /etc/systemd/system/cri-docker.service

        sudo systemctl daemon-reload
        sudo systemctl enable cri-docker.service
        sudo systemctl enable --now cri-docker.socket
      shell: bash

    # NOTE: We apply a workaround as of version 3.0.1 by passing
    #       --egress-selector-mode=disabled by default as not doing so following
    #       modern versions of k3s has led to issues with `kubectl exec` and
    #       `kubectl logs`.
    #
    #       For more details, see
    #       https://github.com/k3s-io/k3s/issues/5633
    #       and https://github.com/jupyterhub/action-k3s-helm/issues/59.
    #
    - name: Setup k3s ${{ inputs.k3s-version }}${{ inputs.k3s-channel }}
      run: |
        echo "::group::Setup k3s ${{ inputs.k3s-version }}${{ inputs.k3s-channel }}"
        if [[ "${{ inputs.metrics-enabled }}" != true ]]; then
          k3s_disable_metrics="--disable metrics-server"
        fi
        if [[ "${{ inputs.traefik-enabled }}" != true ]]; then
          k3s_disable_traefik="--disable traefik"
        fi
        if [[ "${{ inputs.docker-enabled }}" == true ]]; then
          k3s_docker=--container-runtime-endpoint=/run/cri-dockerd.sock
        fi
        # We want to provide a new default value for the --egress-selector-mode
        # flag to workaround the intermittent issue tracked here:
        # https://github.com/k3s-io/k3s/issues/5633#issuecomment-1181424511.
        #
        if [[ "${{ inputs.extra-setup-args }}" != *--egress-selector-mode* ]]; then
          # We check for k3s versions 1.22.10+, 1.23.7+, or 1.24.1+ or more
          # recent where we know the --egress-selector-mode flag is defined.
          # This includes when the version isn't specified or is specified as
          # latest or stable.
          #
          # The verlte function was taken from this stackoverflow post:
          # https://stackoverflow.com/a/4024263/2220152
          #
          verlte() {
            [ "$1" = "`echo -e "$1\n$2" | sort -V | head -n1`" ]
          }
          # If a k3s channel is specified we append a patch version of 99 to it
          # to ensure our verlte comparisons below functions as intended.
          #
          c=${{ inputs.k3s-channel }}
          c=${c:+$c.99}
          v=${{ inputs.k3s-version }}${c}
          if ([[ "$v" != v* ]]) || ([[ "$v" == v1.22.* ]] && verlte "v1.22.10" "$v") || ([[ "$v" == v1.23.* ]] && verlte "v1.23.7" "$v") || (verlte "v1.24.1" "$v"); then
            default_extra_setup_args=--egress-selector-mode=disabled
          fi
        fi
        curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION="${{ inputs.k3s-version }}" INSTALL_K3S_CHANNEL="${{ inputs.k3s-channel }}" sh -s - \
          ${k3s_disable_metrics} \
          ${k3s_disable_traefik} \
          --disable-network-policy \
          --flannel-backend=none \
          ${k3s_docker} \
          ${{ inputs.extra-setup-args }} \
          ${default_extra_setup_args}
        echo "::endgroup::"
      shell: bash

    # By providing a kubeconfig owned by the current user with 600 permissions,
    # kubectl becomes usable without sudo, and helm won't emit warnings about
    # bloated access to group/world.
    - name: Prepare a kubeconfig in ~/.kube/config
      run: |
        echo "::group::Prepare a kubeconfig in ~/.kube/config"
        mkdir -p ~/.kube
        sudo cat /etc/rancher/k3s/k3s.yaml > "$HOME/.kube/config"
        chmod 600 "$HOME/.kube/config"
        echo "KUBECONFIG=$HOME/.kube/config" >> $GITHUB_ENV
        echo "::endgroup::"
      shell: bash

    # Install calico as a CNI to enforce our NetworkPolicies. Note that canal
    # could do this job as well, but we failed to set it up in Travis CI.
    #
    # Below we download the calico.yaml Kubernetes manifest and insert a
    # container_settings section just below the phrase '"type": "calico"' and
    # then `kubectl apply` it.
    #
    # ref: https://rancher.com/docs/k3s/latest/en/installation/network-options/
    #
    - name: Setup calico
      run: |
        echo "::group::Setup calico"
        if [[ "${{ inputs.k3s-version }}${{ inputs.k3s-channel }}" == v1.20* ]]; then
          curl -sfL --output /tmp/calico.yaml https://docs.projectcalico.org/v3.21/manifests/calico.yaml
        else
          curl -sfL --output /tmp/calico.yaml https://raw.githubusercontent.com/projectcalico/calico/v3.24.0/manifests/calico.yaml
        fi
        cat /tmp/calico.yaml \
          | sed '/"type": "calico"/a\
            "container_settings": {\
              "allow_ip_forwarding": true\
            },' \
          | kubectl apply -f -
        echo "::endgroup::"
      shell: bash

    # There will be some waiting for calico to make the k8s Nodes ready and for
    # the k3s related pods to start and become ready, so there is time to
    # install Helm at this point for example.
    - name: Setup Helm ${{ inputs.helm-version }}
      run: |
        echo "::group::Setup Helm ${{ inputs.helm-version }}"
        curl -sf https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | DESIRED_VERSION="${{ inputs.helm-version }}" bash
        echo "::endgroup::"
      shell: bash

    - name: Set version output
      id: set-output
      run: |
        echo "::group::Set version output"
        echo "::set-output name=kubeconfig::$HOME/.kube/config"
        echo "::set-output name=k3s-version::$(k3s --version | sed 's/.*\(v[0-9][^ ]*\).*/\1/')"
        echo "::set-output name=k8s-version::$(k3s --version | sed 's/.*\(v[0-9][^+]*\).*/\1/')"
        echo "::set-output name=calico-version::$(cat /tmp/calico.yaml | grep --max-count=1 "calico/cni:v" | sed 's/.*calico\/cni:\(.*\)/\1/')"
        echo "::set-output name=helm-version::$(helm version --short | sed 's/\([^+]*\).*/\1/')"
        echo "::endgroup::"
      shell: bash

    - name: Wait for calico, coredns, metrics server, traefik
      run: |
        echo "::group::Wait for daemonset/calico-node"
        kubectl rollout status --watch --timeout 600s daemonset/calico-node -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/calico-kube-controllers"
        kubectl rollout status --watch --timeout 600s deployment/calico-kube-controllers -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/coredns"
        kubectl rollout status --watch --timeout 600s deployment/coredns -n kube-system
        echo "::endgroup::"

        echo "::group::Wait for deployment/metrics-server"
        if [[ "${{ inputs.metrics-enabled }}" == true ]]; then
          kubectl rollout status --watch --timeout 600s deployment/metrics-server -n kube-system
        fi
        echo "::endgroup::"

        echo "::group::Wait for deployment/traefik"
        if [[ "${{ inputs.traefik-enabled }}" == true ]]; then
          # NOTE: Different versions of k3s install traefik in different ways,
          #       by waiting for these jobs if they exist, we will be fine no
          #       matter what.
          kubectl wait --for=condition=complete --timeout=600s job/helm-install-traefik-crd -n kube-system || true
          kubectl wait --for=condition=complete --timeout=600s job/helm-install-traefik -n kube-system || true
          kubectl rollout status --watch --timeout 600s deployment/traefik -n kube-system
        fi
        echo "::endgroup::"
      shell: bash
